\chapter{Pesaje de caracteres}
\section*{Introducci\'on}
\index{Car\'acter!pesaje!t\'ecnicas} 
Cuando se habla de pesaje de caracteres en clad\'istica, se refiere a que algunos caracteres sugieren m\'as informaci\'on que otros. El tema es controversial;
la idea de pesaje es central en autores como  \cite{Neff1986}, mientras que para autores como \cite{Kluge1997} es regresar a la subjetividad de la \'epoca de la taxonom\'ia cl\'asica, al imponer a la filogenia un prejuicio de $"$c\'omo$"$ es la evoluci\'on \cite{Kluge1997}; 
%en general los argumentos dados para el pesado diferencial, como incrementar la precisi\'on y disminuir ambiguedad, son cubiertos por los an\'alisis bajo pesos iguales; 
otros autores (por ejemplo, 
\cite{Goloboff1993,Goloboff1995}) 
defienden el uso de pesado, argumentando que es claro tras un an\'alisis filogen\'etico que diferentes caracteres poseen distintos niveles de  informaci\'on; lo cual se hace evidente al multiplicar cualquier cuantificador de homoplasia del car\'acter por el peso inicial que se le asign\'o, en la l\'ogica de pesaje sucesivo 
\cite{KlugeFarris1969}.

Existen dos formas de hacer pesado de caracteres y una tercera que es un criterio de b\'usqueda, que no es  excluyente del pesaje de caracteres. El primero es el pesado \textit{a priori}, antes de empezar el an\'alisis.\index{Car\'acter!pesaje!a priori} 

En la actualidad la forma m\'as com\'un es disminuir el peso del tercer cod\'on en los an\'alisis moleculares. Aunque se han propuesto muchas formas de encontrar a partir de los caracteres un peso inicial, quienes practican pesado del tercer cod\'on no est\'an muy preocupados e insisten que lo importante es diferenciar un tipo de cod\'on de los otros, por ejemplo:  
\cite{Springer2001,Strugnell2014}.


En el pesado \textit{a posteriori} el peso se asigna bas\'andose en un an\'alisis inicial de los datos;\index{Car\'acter!pesaje!a posteriori} se estima la \textit{confianza} del car\'acter, usando por ejemplo, el \'indice de consistencia, o el de retenci\'on, y con base en esos pesos se reinicia el an\'alisis \citep{Farris1969}. En general es el esquema de pesaje m\'as usado. El pregunta clave aqu\'i es: ?`c\'omo se hace este primer an\'alisis? Y despu\'es, ?`c\'omo se termina?. Otro de los problemas de esta forma de pesado radica en la comparaci\'on de los cladogramas, puesto que diferentes juegos de pesos pueden producir diferentes respuestas que no son comparables (a nivel de los estad\'isticos de ajuste, como costos).\\
La tercera forma de $"$pesado$"$ no es ni \textit{a priori}, ni \textit{a posteriori}, ya que en realidad es un criterio de b\'usqueda. Esta forma es conocida como pesado impl\'icito \citep{Goloboff1993}. Este procedimiento utiliza la confianza del car\'acter (con una funci\'on c\'oncava de homoplasia) y utiliza ese valor como criterio \'optimo; el problema de este m\'etodo, de hecho el de cualquier m\'etodo, es c\'omo escoger entre las diferentes funciones.
\index{Car\'acter!pesaje!sucesivo}
El pesado sucesivo es muy popular para $"$reducir$"$ la cantidad de \'arboles m\'as parsimoniosos \citep{Carpenter1988}, aplicaci\'on que no es correcta ya que es una metodolog\'ia con su propia l\'ogica, definir los pesos de acuerdo al comportamiento en las b\'usquedas previas, por lo que los resultados no tienen que coincidir con los de pesos iguales, ni en topolog\'ia ni en n\'umero de soluciones (impl\'icito en \cite{Goloboff1995}).

Para iniciar las rondas de pesado, \cite{Farris1969} propuso comenzar bas\'andose en la compatibilidad de caracteres (que no se contradicen entre s\'i). En la actualidad la forma m\'as com\'un es iniciar con un \'arbol de pesos iguales. \cite{Kjer2001} propusieron comenzar con el mejor resultado de varios \'arboles producto de \textit{bootstrap}
\index{Remuestreo!bootstrap} 
(u otro m\'etodo que produzca pseudor\'eplicas).  

Dado que se espera que el an\'alisis sea autoconsistente  \citep{Farris1969}, dos r\'eplicas consecutivas deben generar  los mismos \'arboles (y por lo tanto los mismos pesos). La autoconsistencia se puede ver afectada por el hecho de tener gran cantidad de \'arboles \'optimos, por lo que es importante limitar el n\'umero de iteraciones. \cite{Kjer2001} proponen no iterar y solo mantener los pesos dados por los \'arboles de las pseudor\'eplicas.

\cite{Farris2001} busc\'o solucionar simult\'aneamente ambos problemas. Propuso comenzar con un \'arbol donde se ha hecho \textit{jackknife} con probabilidad de 0.5, restaurar luego todos los caracteres y comenzar a partir de los estad\'isticos del \'arbol producto de la permutaci\'on e iterar;\index{Remuestreo!jackknife} el proceso se repite varias veces. \cite{Farris2001} argumenta que si los pesos son independientes del punto inicial, las diferentes r\'eplicas producir\'an aproximadamente los mismos resultados (los resultados se muestran como un \'arbol consenso de la mayor\'ia de las diferentes r\'eplicas).

El m\'etodo de \cite{Goloboff1993} sigue la l\'ogica de parsimonia tradicional, y aunque \cite{Goloboff1993} ve\'ia su m\'etodo como un refinamiento de pesado sucesivo, este pesaje se puede usar igualmente en coordinaci\'on con pesado impl\'icito. La forma com\'un de pesado impl\'icito es usar una funci\'on c\'oncava de la forma $\frac{k}{k + h}$, donde $k$ es la constante de concavidad y $h$ la homoplasia del car\'acter. Cuanto mayor sea la constante de concavidad, menor es la diferencia entre los caracteres muy homopl\'asicos y los poco o no homopl\'asicos, por lo que es equivalente a parsimonia lineal.
\index{B\'usqueda!funciones concavas}

\section*{T\'ecnicas}

Para la matriz de datos (\Fname{datos.pesado.dat}).

\begin{enumerate}
	\item En \Pname{PAUP*}
	se pueden definir juegos de caracteres usando el c\'odigo X - .$\backslash$ N, donde X es el n\'umero del car\'acter donde se empieza y N el n\'umero de posiciones en los que se vuelve a aplicar la opci\'on. Por lo tanto la instrucci\'on \cmd{weights 3:all;} todos los caracteres tendr\'an peso de 3 y con \cmd{weights 1: 3 - .$\backslash$ 3;} cada tercer car\'acter, a partir del car\'acter 3 ser\'a pesado con 1. Usted puede chequear esto usando \cmd{cstatus full=yes;} que le mostrar\'a el peso de todos los caracteres y deben verse en la secuencia 3 3 1 3 3 1...,
	tambi\'en tiene implementado una opci\'on para tomar pesos a partir de los \'arboles en memoria. Esa opci\'on es \cmd{reweight} en la que se pueden modificar el tipo de pesado, qu\'e valor se va a utilizar y la escala de los pesos. !`Use la ayuda en l\'inea para manipular estos valores!.

	\begin{enumerate}
		\item  Abra la matriz y realice una b\'usqueda simple.
		\item Repita la b\'usqueda pesando diferencialmente el tercer cod\'on (por ejemplo asignandole un peso de 0), primero creamos la partici\'on:
		\Cmd{charset  terceraPosicion=3-.$\backslash$ 3;}

		y luego se asigna el peso \Cmd{weight 0 :terceraPosicion;}

		Compare los resultados con los de la matriz sin pesado diferencial.

		\item Coloque todos los pesos iguales y realice una b\'usqueda con pesado sucesivo, itere un m\'aximo de 10 veces. Chequee si los pesos se estabilizaron revisando el costo de los \'arboles usando \cmd{pscores;}.
	\end{enumerate}
	
	\item En \Pname{TNT} el pesado impl\'icito se activa utilizando \cmd{piwe=N;} donde N es el valor de concavidad a usar. Con \Pname{PAUP*} se activa usando \Cmd{pset Goloboff=yes gk=(N-1);} La notaci\'on de N-1 es necesaria ya que \Pname{PAUP*} comienza con 0 y suma uno (t\'ecnicamente es como comenzar desde 1). Tanto en \Pname{TNT} como en \Pname{PAUP*} el l\'imite es de 32000 (lo cual es pr\'acticamente equivalente a parsimonia lineal). Adem\'as \Pname{TNT} y \Pname{PAUP*} usan todos los valores decimales, por lo cual es recomendable recurrir a alguna medida de soporte para los nodos, con lo que se evita la sobre-resoluci\'on. A diferencia de \Pname{PAUP*}, \Pname{TNT} usa una funci\'on a minimizar\footnote{el inverso de la usada en \Pname{PIWE}: $\frac{h}{k + h}$}; para comparar los reportes del ajuste generados en \Pname{PAUP*}, puede obtener el ajuste usando \cmd{fit*;}.
	En \Pname{PAUP*} use \Cmd{pscores gfit=yes;}
	\Pname{TNT} permite definir su propia funci\'on de concavidad usando \cmd{piwe [A B C...;}, donde A es el fit para 0 pasos extra, B para 1, C para 2 y asi sucesivamente. 

	\item Tanto en \Pname{TNT}  como en \Pname{PAUP*}:
	\begin{enumerate}
		\item Con los caracteres con pesos iguales, active los pesos impl\'icados con k=1, y haga una b\'usqueda.
		\item Revise el soporte de los nodos usando \textit{jackknife} (use pocas r\'eplicas, m\'aximo 100).
		\item Repita los an\'alisis con valores de k de 3, 6 y 10.
	\end{enumerate}
	
\end{enumerate}

\preguntaGral{
	\begin{itemize}
		\item Compare sus resultados (topolog\'ias y caracteres en los nodos) con todos los m\'etodos de pesado utilizados. ?`En qu\'e se parecen y en qu\'e se diferencian los resultados?
		\item Usted debi\'o definir una forma de pesaje del tercer cod\'on. Defienda su esquema de pesado y comp\'arelo con el de sus compa\~neros.
		\item Dados los resultados que encontr\'o al medir el soporte de los nodos, ?`cree usted que hay sobreresoluci\'on en los datos usados?
		\item Escriba un ensayo corto (de media p\'agina) donde presente su posici\'on con respecto al pesado de caracteres, tenga en cuenta las siguentes preguntas:
		\begin{itemize}
			\item  ?`Est\'a a favor o en contra?  ?`por qu\'e? 
			\item ?`Cu\'ales son las ventajas y problemas que ofrece su posici\'on?
			\item ?`El pesaje contradice la l\'ogica de agrupamiento por homolog\'ias?
		\end{itemize}
	\end{itemize}

}

\section*{Literatura recomendada}

\cite{Farris1969} [La idea original de pesar usando la informaci\'on derivada de los cladogramas].


\cite{Goloboff1995} [Una defensa de pesado impl\'icito].\\
\cite{Goloboffetal2008} [Un an\'alisis emp\'irico que muestra que pesaje es un mejor predictor que parsimonia lineal].\\
\cite{Kluge1997} [Un ataque a todas las formas de pesaje].
